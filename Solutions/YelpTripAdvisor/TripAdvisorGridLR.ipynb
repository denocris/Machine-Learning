{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_data = open(\"data/data_cleaned_head1000/textfeatures_head1000\", \"r\")\n",
    "target_data = open(\"data/data_cleaned_head1000/starstarget_head1000\", \"r\")\n",
    "#features_data = open(\"data/data_cleaned/textfeatures0\", \"r\")\n",
    "#target_data = open(\"data/data_cleaned/starstarget0\", \"r\")\n",
    "text = [line for line in features_data]\n",
    "target = [int(line.split()[0]) for line in target_data]\n",
    "\n",
    "target = [ 1 if target[i] >=3 else 0 for i in range(len(target ))]\n",
    "dataset = [[text[i], target[i]] for i in range(len(target))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancing the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_pos = target.count(1)\n",
    "target_neg = target.count(0)\n",
    "ratio = float(target_neg) / target_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def rebalance(dataset_to_reb, length, ratio): \n",
    "    reb_dataset = []\n",
    "    for i in range(length):\n",
    "        if dataset_to_reb[i][1] == 0:\n",
    "            reb_dataset.append(dataset_to_reb[i])\n",
    "        else:\n",
    "            rnd = random.random()\n",
    "            if rnd < ratio:\n",
    "                reb_dataset.append(dataset_to_reb[i])\n",
    "    return reb_dataset\n",
    "\n",
    "reb_dataset = rebalance(dataset, len(target), ratio)\n",
    "\n",
    "reb_text = [ tx for [tx,tg] in reb_dataset]\n",
    "reb_target = [ tg for [tx,tg] in reb_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First selection of stop_words\n",
    "\n",
    "default_stop_words = ['all', 'six', 'less', 'being', 'indeed', 'over', 'move', 'anyway', 'not', 'fifty', 'four', 'own', 'through', 'yourselves', 'go', 'where', 'mill', 'only', 'find', 'before', 'one', 'whose', 'system', 'how', 'somewhere', 'with', 'thick', 'show', 'had', 'enough', 'should', 'to', 'must', 'whom', 'seeming', 'under', 'ours', 'has', 'might', 'thereafter', 'latterly', 'do', 'them', 'his', 'around', 'than', 'get', 'very', 'de', 'none', 'cannot', 'every', 'whether', 'they', 'front', 'during', 'thus', 'now', 'him', 'nor', 'name', 'several', 'hereafter', 'always', 'who', 'cry', 'whither', 'this', 'someone', 'either', 'each', 'become', 'thereupon', 'sometime', 'side', 'two', 'therein', 'twelve', 'because', 'often', 'ten', 'our', 'eg', 'some', 'back', 'up', 'namely', 'towards', 'are', 'further', 'beyond', 'ourselves', 'yet', 'out', 'even', 'will', 'what', 'still', 'for', 'bottom', 'mine', 'since', 'please', 'forty', 'per', 'its', 'everything', 'behind', 'un', 'above', 'between', 'it', 'neither', 'seemed', 'ever', 'across', 'she', 'somehow', 'be', 'we', 'full', 'never', 'sixty', 'however', 'here', 'otherwise', 'were', 'whereupon', 'nowhere', 'although', 'found', 'alone', 're', 'along', 'fifteen', 'by', 'both', 'about', 'last', 'would', 'anything', 'via', 'many', 'could', 'thence', 'put', 'against', 'keep', 'etc', 'amount', 'became', 'ltd', 'hence', 'onto', 'or', 'con', 'among', 'already', 'co', 'afterwards', 'formerly', 'within', 'seems', 'into', 'others', 'while', 'whatever', 'except', 'down', 'hers', 'everyone', 'done', 'least', 'another', 'whoever', 'moreover', 'couldnt', 'throughout', 'anyhow', 'yourself', 'three', 'from', 'her', 'few', 'together', 'top', 'there', 'due', 'been', 'next', 'anyone', 'eleven', 'much', 'call', 'therefore', 'interest', 'then', 'thru', 'themselves', 'hundred', 'was', 'sincere', 'empty', 'more', 'himself', 'elsewhere', 'mostly', 'on', 'fire', 'am', 'becoming', 'hereby', 'amongst', 'else', 'part', 'everywhere', 'too', 'herself', 'former', 'those', 'he', 'me', 'myself', 'made', 'twenty', 'these', 'bill', 'cant', 'us', 'until', 'besides', 'nevertheless', 'below', 'anywhere', 'nine', 'can', 'of', 'your', 'toward', 'my', 'something', 'and', 'whereafter', 'whenever', 'give', 'almost', 'wherever', 'is', 'describe', 'beforehand', 'herein', 'an', 'as', 'itself', 'at', 'have', 'in', 'seem', 'whence', 'ie', 'any', 'fill', 'again', 'hasnt', 'inc', 'thereby', 'thin', 'no', 'perhaps', 'latter', 'meanwhile', 'when', 'detail', 'same', 'wherein', 'beside', 'also', 'that', 'other', 'take', 'which', 'becomes', 'you', 'if', 'nobody', 'see', 'though', 'may', 'after', 'upon', 'most', 'hereupon', 'eight', 'but', 'serious', 'nothing', 'such', 'why', 'a', 'off', 'whereby', 'third', 'i', 'whole', 'noone', 'sometimes', 'well', 'amoungst', 'yours', 'their', 'rather', 'without', 'so', 'five', 'the', 'first', 'whereas', 'once']\n",
    "list_word_to_remove = ['not']\n",
    "my_stop_words = [word for word in default_stop_words if word not in list_word_to_remove]\n",
    "\n",
    "my_stop_words.append('ve') \n",
    "my_stop_words.append('ll')\n",
    "my_stop_words.append('got')\n",
    "my_stop_words.append('know')\n",
    "my_stop_words.append('15')\n",
    "my_stop_words.append('30')\n",
    "my_stop_words.append('20')\n",
    "my_stop_words.append('50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yak52/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reb_text, reb_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model: Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 ms, sys: 31.3 ms, total: 65.1 ms\n",
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import pipeline\n",
    "\n",
    "\n",
    "def my_pipeline_logreg(thres):\n",
    "    nsw = np.loadtxt(\"data/stop_words/my_stop_words_thr_%.2f.txt\" %thres, dtype=str)\n",
    "    pipe = pipeline.Pipeline([\n",
    "                            ('count_vectorizer', CountVectorizer(stop_words = list(nsw), max_df = 0.9, min_df = 10)),\n",
    "                            #('count_vectorizer', CountVectorizer(stop_words = my_stop_words, max_df = 0.9, min_df = 10)),\n",
    "                            ('tf_idf',TfidfTransformer()),\n",
    "                            ('model',LogisticRegression(penalty='l2', \n",
    "                                                           dual=False, \n",
    "                                                           tol=0.0001, \n",
    "                                                           C=1.0, \n",
    "                                                           fit_intercept=True, \n",
    "                                                           intercept_scaling=1, \n",
    "                                                           class_weight=None, \n",
    "                                                           random_state=None, \n",
    "                                                           solver='liblinear', \n",
    "                                                           max_iter=100,\n",
    "                                                           multi_class='ovr',\n",
    "                                                           verbose=0, \n",
    "                                                           warm_start=False, \n",
    "                                                           n_jobs=1))\n",
    "                         ])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Optimisation: Grid Search for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import DataFrame\n",
    "\n",
    "pipe = my_pipeline_logreg(0.5)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "                    pipe,\n",
    "                    {\n",
    "                        #\"count_vectorizer__min_df\": range(1,10)+range(10,30,5),\n",
    "                        #\"model__C\": [0.1, 0.5, 1.0, 3.0, 5.0, 10, 20, 50, 80]\n",
    "                        \"count_vectorizer__min_df\": range(1,3),\n",
    "                        \"model__C\": [0.1, 0.5]\n",
    "                    },\n",
    "                    cv=2,  # 5-fold cross validation\n",
    "                    n_jobs=4,  # run each hyperparameter in one of two parallel jobs\n",
    "                    scoring=\"accuracy\" # what could happen selecting \"precision\" as scoring measure?\n",
    "                )\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "dictionary = gs.cv_results_\n",
    "\n",
    "import cPickle as pickle\n",
    "with open('lr_grid_results_test.csv', 'wb') as fp:\n",
    "    pickle.dump(dictionary, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lr_grid_results_test.csv', 'rb') as fp:\n",
    "    mydict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "results = DataFrame(data = mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_count_vectorizer__min_df</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067637</td>\n",
       "      <td>0.058116</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{u'model__C': 0.1, u'count_vectorizer__min_df'...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.570652</td>\n",
       "      <td>0.788043</td>\n",
       "      <td>0.559783</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081349</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{u'model__C': 0.5, u'count_vectorizer__min_df'...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.788043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733696</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074534</td>\n",
       "      <td>0.054585</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.823370</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{u'model__C': 0.1, u'count_vectorizer__min_df'...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062522</td>\n",
       "      <td>0.043682</td>\n",
       "      <td>0.777174</td>\n",
       "      <td>0.975543</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{u'model__C': 0.5, u'count_vectorizer__min_df'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.002717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.067637         0.058116         0.565217          0.793478   \n",
       "1       0.081349         0.052667         0.760870          0.994565   \n",
       "2       0.074534         0.054585         0.619565          0.823370   \n",
       "3       0.062522         0.043682         0.777174          0.975543   \n",
       "\n",
       "  param_count_vectorizer__min_df param_model__C  \\\n",
       "0                              1            0.1   \n",
       "1                              1            0.5   \n",
       "2                              2            0.1   \n",
       "3                              2            0.5   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {u'model__C': 0.1, u'count_vectorizer__min_df'...                4   \n",
       "1  {u'model__C': 0.5, u'count_vectorizer__min_df'...                2   \n",
       "2  {u'model__C': 0.1, u'count_vectorizer__min_df'...                3   \n",
       "3  {u'model__C': 0.5, u'count_vectorizer__min_df'...                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.570652            0.788043           0.559783   \n",
       "1           0.788043            1.000000           0.733696   \n",
       "2           0.619565            0.831522           0.619565   \n",
       "3           0.809783            0.978261           0.744565   \n",
       "\n",
       "   split1_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.798913      0.018851        0.002328        0.005435   \n",
       "1            0.989130      0.003168        0.005807        0.027174   \n",
       "2            0.815217      0.002219        0.000678        0.000000   \n",
       "3            0.972826      0.005173        0.011648        0.032609   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.005435  \n",
       "1         0.005435  \n",
       "2         0.008152  \n",
       "3         0.002717  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
